{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6af7bc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (41458, 29)\n",
      "\n",
      "FIFA version distribution:\n",
      "fifa_version\n",
      "17.0    8889\n",
      "18.0    8814\n",
      "19.0    8777\n",
      "20.0    8091\n",
      "21.0    6887\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Target distribution:\n",
      "big_potential\n",
      "0    31162\n",
      "1    10296\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../data/feature_engineered_data.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFIFA version distribution:\")\n",
    "print(df['fifa_version'].value_counts().sort_index())\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(df['big_potential'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dab2282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (FIFA 17-20): 34571 samples\n",
      "Test (FIFA 21): 6887 samples\n",
      "big_potential\n",
      "0    25968\n",
      "1     8603\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define temporal splits\n",
    "train_versions = [17.0, 18.0, 19.0,20.0]\n",
    "\n",
    "test_version = 21.0\n",
    "\n",
    "\n",
    "df_train = df[df['fifa_version'].isin(train_versions)]\n",
    "\n",
    "df_test = df[df['fifa_version'] == test_version]\n",
    "\n",
    "print(f\"Train (FIFA 17-20): {len(df_train)} samples\")\n",
    "\n",
    "print(f\"Test (FIFA 21): {len(df_test)} samples\")\n",
    "print(df_train[\"big_potential\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ddb97ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 27\n",
      "Features: ['age', 'physic', 'mentality_aggression', 'mentality_interceptions', 'power_stamina', 'power_strength', 'defending_marking_awareness', 'power_jumping', 'defending_standing_tackle', 'defending_sliding_tackle', 'attacking_heading_accuracy', 'mentality_composure', 'movement_reactions', 'skill_long_passing', 'skill_dribbling', 'skill_fk_accuracy', 'skill_ball_control', 'attacking_crossing', 'power_shot_power', 'attacking_finishing', 'skill_curve', 'movement_balance', 'attacking_volleys', 'power_long_shots', 'mentality_vision', 'mentality_penalties', 'movement_agility']\n",
      "(34571, 27)\n",
      "(6887, 27)\n"
     ]
    }
   ],
   "source": [
    "feature_columns = [col for col in df.columns if col not in ['fifa_version', 'big_potential']]\n",
    "target = 'big_potential'\n",
    "\n",
    "print(f\"Number of features: {len(feature_columns)}\")\n",
    "print(f\"Features: {feature_columns}\")\n",
    "\n",
    "# Prepare datasets\n",
    "X_train = df_train[feature_columns]\n",
    "y_train = df_train[target]\n",
    "print(X_train.shape)\n",
    "X_test = df_test[feature_columns]\n",
    "y_test = df_test[target]\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8f7df1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f25646d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "APPLYING SMOTE OVERSAMPLING\n",
      "======================================================================\n",
      "\n",
      "Class distribution BEFORE SMOTE:\n",
      "No Big Potential (0): 25968\n",
      "Big Potential (1): 8603\n",
      "Ratio: 3.02:1\n",
      "\n",
      "Class distribution AFTER SMOTE:\n",
      "No Big Potential (0): 25968\n",
      "Big Potential (1): 25968\n",
      "Ratio: 1.00:1\n",
      "\n",
      "Total samples after SMOTE: 51936\n",
      "Original samples: 34571\n",
      "New samples generated: 17365\n"
     ]
    }
   ],
   "source": [
    "# Apply SMOTE oversampling to balance the training set\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"APPLYING SMOTE OVERSAMPLING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check class distribution before SMOTE\n",
    "print(\"\\nClass distribution BEFORE SMOTE:\")\n",
    "print(f\"No Big Potential (0): {(y_train == 0).sum()}\")\n",
    "print(f\"Big Potential (1): {(y_train == 1).sum()}\")\n",
    "print(f\"Ratio: {(y_train == 0).sum() / (y_train == 1).sum():.2f}:1\")\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42, k_neighbors=5)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Check class distribution after SMOTE\n",
    "print(\"\\nClass distribution AFTER SMOTE:\")\n",
    "print(f\"No Big Potential (0): {(y_train_resampled == 0).sum()}\")\n",
    "print(f\"Big Potential (1): {(y_train_resampled == 1).sum()}\")\n",
    "print(f\"Ratio: {(y_train_resampled == 0).sum() / (y_train_resampled == 1).sum():.2f}:1\")\n",
    "print(f\"\\nTotal samples after SMOTE: {len(X_train_resampled)}\")\n",
    "print(f\"Original samples: {len(X_train_scaled)}\")\n",
    "print(f\"New samples generated: {len(X_train_resampled) - len(X_train_scaled)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bebccaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TRAINING LOGISTIC REGRESSION MODEL\n",
      "======================================================================\n",
      "\n",
      "Training Logistic Regression on resampled data...\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TRAINING LOGISTIC REGRESSION MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Initialize Logistic Regression with balanced class weights\n",
    "lr_model = LogisticRegression(\n",
    "    random_state=42,\n",
    "    solver='lbfgs',  # Good for small datasets\n",
    "    C=10,\n",
    "    penalty='l2',  # Regularization strength (inverse of regularization)\n",
    "    \n",
    ")\n",
    "\n",
    "print(\"\\nTraining Logistic Regression on resampled data...\")\n",
    "lr_model.fit(X_train_resampled, y_train_resampled)\n",
    "print(\"Training completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdf79f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOGISTIC REGRESSION - Training Set (Resampled) Metrics\n",
      "======================================================================\n",
      "\n",
      "Accuracy:  0.6594\n",
      "Precision: 0.6494\n",
      "Recall:    0.6928\n",
      "F1 Score:  0.6704\n",
      "ROC-AUC:   0.7124\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Classification Report:\n",
      "----------------------------------------------------------------------\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "No Big Potential       0.67      0.63      0.65     25968\n",
      "   Big Potential       0.65      0.69      0.67     25968\n",
      "\n",
      "        accuracy                           0.66     51936\n",
      "       macro avg       0.66      0.66      0.66     51936\n",
      "    weighted avg       0.66      0.66      0.66     51936\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Confusion Matrix:\n",
      "----------------------------------------------------------------------\n",
      "                  Predicted\n",
      "                  No BP    BP\n",
      "Actual No BP     16254   9714\n",
      "Actual BP         7977  17991\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on training set (resampled)\n",
    "print(\"=\"*70)\n",
    "print(\"LOGISTIC REGRESSION - Training Set (Resampled) Metrics\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "y_train_pred = lr_model.predict(X_train_resampled)\n",
    "y_train_proba = lr_model.predict_proba(X_train_resampled)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_train_resampled, y_train_pred)\n",
    "precision = precision_score(y_train_resampled, y_train_pred)\n",
    "recall = recall_score(y_train_resampled, y_train_pred)\n",
    "f1 = f1_score(y_train_resampled, y_train_pred)\n",
    "roc_auc = roc_auc_score(y_train_resampled, y_train_proba)\n",
    "\n",
    "print(f\"\\nAccuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1 Score:  {f1:.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Classification Report:\")\n",
    "print(\"-\"*70)\n",
    "print(classification_report(y_train_resampled, y_train_pred, target_names=['No Big Potential', 'Big Potential']))\n",
    "\n",
    "print(\"-\"*70)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(\"-\"*70)\n",
    "cm = confusion_matrix(y_train_resampled, y_train_pred)\n",
    "print(f\"                  Predicted\")\n",
    "print(f\"                  No BP    BP\")\n",
    "print(f\"Actual No BP     {cm[0,0]:5d}  {cm[0,1]:5d}\")\n",
    "print(f\"Actual BP        {cm[1,0]:5d}  {cm[1,1]:5d}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a18f8930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOGISTIC REGRESSION - Original Training Set (Before SMOTE) Metrics\n",
      "======================================================================\n",
      "\n",
      "Accuracy:  0.6389\n",
      "Precision: 0.3751\n",
      "Recall:    0.6779\n",
      "F1 Score:  0.4830\n",
      "ROC-AUC:   0.7049\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Classification Report:\n",
      "----------------------------------------------------------------------\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "No Big Potential       0.85      0.63      0.72     25968\n",
      "   Big Potential       0.38      0.68      0.48      8603\n",
      "\n",
      "        accuracy                           0.64     34571\n",
      "       macro avg       0.61      0.65      0.60     34571\n",
      "    weighted avg       0.74      0.64      0.66     34571\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Confusion Matrix:\n",
      "----------------------------------------------------------------------\n",
      "                  Predicted\n",
      "                  No BP    BP\n",
      "Actual No BP     16254   9714\n",
      "Actual BP         2771   5832\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on original training set (before SMOTE)\n",
    "print(\"=\"*70)\n",
    "print(\"LOGISTIC REGRESSION - Original Training Set (Before SMOTE) Metrics\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "y_train_orig_pred = lr_model.predict(X_train_scaled)\n",
    "y_train_orig_proba = lr_model.predict_proba(X_train_scaled)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy_orig = accuracy_score(y_train, y_train_orig_pred)\n",
    "precision_orig = precision_score(y_train, y_train_orig_pred)\n",
    "recall_orig = recall_score(y_train, y_train_orig_pred)\n",
    "f1_orig = f1_score(y_train, y_train_orig_pred)\n",
    "roc_auc_orig = roc_auc_score(y_train, y_train_orig_proba)\n",
    "\n",
    "print(f\"\\nAccuracy:  {accuracy_orig:.4f}\")\n",
    "print(f\"Precision: {precision_orig:.4f}\")\n",
    "print(f\"Recall:    {recall_orig:.4f}\")\n",
    "print(f\"F1 Score:  {f1_orig:.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc_orig:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Classification Report:\")\n",
    "print(\"-\"*70)\n",
    "print(classification_report(y_train, y_train_orig_pred, target_names=['No Big Potential', 'Big Potential']))\n",
    "\n",
    "print(\"-\"*70)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(\"-\"*70)\n",
    "cm_orig = confusion_matrix(y_train, y_train_orig_pred)\n",
    "print(f\"                  Predicted\")\n",
    "print(f\"                  No BP    BP\")\n",
    "print(f\"Actual No BP     {cm_orig[0,0]:5d}  {cm_orig[0,1]:5d}\")\n",
    "print(f\"Actual BP        {cm_orig[1,0]:5d}  {cm_orig[1,1]:5d}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd905a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOGISTIC REGRESSION - Test Set (FIFA 21) Metrics\n",
      "======================================================================\n",
      "\n",
      "Accuracy:  0.6361\n",
      "Precision: 0.3695\n",
      "Recall:    0.6799\n",
      "F1 Score:  0.4788\n",
      "ROC-AUC:   0.6983\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Classification Report:\n",
      "----------------------------------------------------------------------\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "No Big Potential       0.86      0.62      0.72      5194\n",
      "   Big Potential       0.37      0.68      0.48      1693\n",
      "\n",
      "        accuracy                           0.64      6887\n",
      "       macro avg       0.61      0.65      0.60      6887\n",
      "    weighted avg       0.74      0.64      0.66      6887\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Confusion Matrix:\n",
      "----------------------------------------------------------------------\n",
      "                  Predicted\n",
      "                  No BP    BP\n",
      "Actual No BP      3230   1964\n",
      "Actual BP          542   1151\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "print(\"=\"*70)\n",
    "print(\"LOGISTIC REGRESSION - Test Set (FIFA 21) Metrics\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "y_test_pred = lr_model.predict(X_test_scaled)\n",
    "y_test_proba = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "precision_test = precision_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "roc_auc_test = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "print(f\"\\nAccuracy:  {accuracy_test:.4f}\")\n",
    "print(f\"Precision: {precision_test:.4f}\")\n",
    "print(f\"Recall:    {recall_test:.4f}\")\n",
    "print(f\"F1 Score:  {f1_test:.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc_test:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Classification Report:\")\n",
    "print(\"-\"*70)\n",
    "print(classification_report(y_test, y_test_pred, target_names=['No Big Potential', 'Big Potential']))\n",
    "\n",
    "print(\"-\"*70)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(\"-\"*70)\n",
    "cm_test = confusion_matrix(y_test, y_test_pred)\n",
    "print(f\"                  Predicted\")\n",
    "print(f\"                  No BP    BP\")\n",
    "print(f\"Actual No BP     {cm_test[0,0]:5d}  {cm_test[0,1]:5d}\")\n",
    "print(f\"Actual BP        {cm_test[1,0]:5d}  {cm_test[1,1]:5d}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1181ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "METRICS SUMMARY COMPARISON\n",
      "======================================================================\n",
      "\n",
      "Metric          Resampled Train    Original Train     Test Set       \n",
      "----------------------------------------------------------------------\n",
      "Accuracy        0.6595             0.6389             0.6363         \n",
      "Precision       0.6495             0.3752             0.3696         \n",
      "Recall          0.6929             0.6779             0.6799         \n",
      "F1 Score        0.6705             0.4830             0.4789         \n",
      "ROC-AUC         0.7124             0.7049             0.6983         \n"
     ]
    }
   ],
   "source": [
    "# Summary comparison\n",
    "print(\"=\"*70)\n",
    "print(\"METRICS SUMMARY COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n{'Metric':<15} {'Resampled Train':<18} {'Original Train':<18} {'Test Set':<15}\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Accuracy':<15} {accuracy:<18.4f} {accuracy_orig:<18.4f} {accuracy_test:<15.4f}\")\n",
    "print(f\"{'Precision':<15} {precision:<18.4f} {precision_orig:<18.4f} {precision_test:<15.4f}\")\n",
    "print(f\"{'Recall':<15} {recall:<18.4f} {recall_orig:<18.4f} {recall_test:<15.4f}\")\n",
    "print(f\"{'F1 Score':<15} {f1:<18.4f} {f1_orig:<18.4f} {f1_test:<15.4f}\")\n",
    "print(f\"{'ROC-AUC':<15} {roc_auc:<18.4f} {roc_auc_orig:<18.4f} {roc_auc_test:<15.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfbe60c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
