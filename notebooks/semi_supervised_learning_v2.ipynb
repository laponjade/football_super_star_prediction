{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53a4fca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (41458, 17)\n",
      "\n",
      "FIFA version distribution:\n",
      "fifa_version\n",
      "17.0    8889\n",
      "18.0    8814\n",
      "19.0    8777\n",
      "20.0    8091\n",
      "21.0    6887\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Target distribution:\n",
      "big_potential\n",
      "0    31162\n",
      "1    10296\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../data/feature_engineered_data_v2.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFIFA version distribution:\")\n",
    "print(df['fifa_version'].value_counts().sort_index())\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(df['big_potential'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "192b6105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (FIFA 17-20): 34571 samples\n",
      "Validation (FIFA 21): 6887 samples\n",
      "Test (FIFA 21): 6887 samples\n"
     ]
    }
   ],
   "source": [
    "# Define temporal splits\n",
    "train_versions = [17.0, 18.0, 19.0,20.0]\n",
    "val_version = 21.0\n",
    "test_version = 21.0\n",
    "\n",
    "# Split data by FIFA version\n",
    "df_train = df[df['fifa_version'].isin(train_versions)]\n",
    "df_val = df[df['fifa_version'] == val_version]\n",
    "df_test = df[df['fifa_version'] == test_version]\n",
    "\n",
    "print(f\"Train (FIFA 17-20): {len(df_train)} samples\")\n",
    "print(f\"Validation (FIFA 21): {len(df_val)} samples\")\n",
    "print(f\"Test (FIFA 21): {len(df_test)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad902a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 15\n",
      "Features: ['age', 'mentality_interceptions', 'defending', 'defending_standing_tackle', 'defending_sliding_tackle', 'attacking_heading_accuracy', 'skill_dribbling', 'attacker_position', 'skill_ball_control', 'midfielder_position', 'attacking_finishing', 'attacking_volleys', 'attacking_short_passing', 'mentality_positioning', 'shooting']\n"
     ]
    }
   ],
   "source": [
    "# All columns except fifa_version and big_potential are features\n",
    "feature_columns = [col for col in df.columns if col not in ['fifa_version', 'big_potential']]\n",
    "target = 'big_potential'\n",
    "\n",
    "print(f\"Number of features: {len(feature_columns)}\")\n",
    "print(f\"Features: {feature_columns}\")\n",
    "\n",
    "# Prepare datasets\n",
    "X_train = df_train[feature_columns]\n",
    "y_train = df_train[target]\n",
    "\n",
    "X_val = df_val[feature_columns]\n",
    "y_val = df_val[target]\n",
    "\n",
    "X_test = df_test[feature_columns]\n",
    "y_test = df_test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "726ce20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled samples: 6914 (20.0%)\n",
      "Unlabeled samples: 27657 (80.0%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Stratified split: 10% labeled, 90% unlabeled from training data\n",
    "X_labeled, X_unlabeled, y_labeled, y_unlabeled_true = train_test_split(\n",
    "    X_train, y_train, \n",
    "    test_size=0.8,  # 90% unlabeled\n",
    "    stratify=y_train, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create unlabeled labels (-1 for semi-supervised algorithms)\n",
    "y_unlabeled = np.full(len(y_unlabeled_true), -1)\n",
    "\n",
    "# Combine for semi-supervised training\n",
    "X_train_ssl = np.vstack([X_labeled.values, X_unlabeled.values])\n",
    "y_train_ssl = np.concatenate([y_labeled.values, y_unlabeled])\n",
    "\n",
    "print(f\"Labeled samples: {len(y_labeled)} ({len(y_labeled)/len(y_train)*100:.1f}%)\")\n",
    "print(f\"Unlabeled samples: {len(y_unlabeled)} ({len(y_unlabeled)/len(y_train)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f97ba738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_train_ssl))\n",
    "print(type(X_train_ssl))\n",
    "X_val_array = X_val.values if hasattr(X_val, 'values') else X_val\n",
    "print(type(X_val_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d29098f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_ssl_scaled = scaler.fit_transform(X_train_ssl)\n",
    "X_val_array_scaled = scaler.transform(X_val_array)\n",
    "X_labeled_scaled = scaler.transform(X_labeled.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52f1729a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution across splits:\n",
      "Train total: {0: 25968, 1: 8603}\n",
      "Labeled only: {0: 5193, 1: 1721}\n",
      "Validation: {0: 5194, 1: 1693}\n",
      "Test: {0: 5194, 1: 1693}\n"
     ]
    }
   ],
   "source": [
    "print(\"Class distribution across splits:\")\n",
    "print(f\"Train total: {y_train.value_counts().to_dict()}\")\n",
    "print(f\"Labeled only: {y_labeled.value_counts().to_dict()}\")\n",
    "print(f\"Validation: {y_val.value_counts().to_dict()}\")\n",
    "print(f\"Test: {y_test.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "609759b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BASELINE MODEL - Validation Set (FIFA 21) Metrics\n",
      "============================================================\n",
      "\n",
      "Accuracy:  0.6851\n",
      "Precision: 0.4085\n",
      "Recall:    0.6273\n",
      "F1 Score:  0.4948\n",
      "ROC-AUC:   0.7245\n",
      "\n",
      "------------------------------------------------------------\n",
      "Classification Report:\n",
      "------------------------------------------------------------\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "No Big Potential       0.85      0.70      0.77      5194\n",
      "   Big Potential       0.41      0.63      0.49      1693\n",
      "\n",
      "        accuracy                           0.69      6887\n",
      "       macro avg       0.63      0.67      0.63      6887\n",
      "    weighted avg       0.74      0.69      0.70      6887\n",
      "\n",
      "------------------------------------------------------------\n",
      "Confusion Matrix:\n",
      "------------------------------------------------------------\n",
      "                  Predicted\n",
      "                  No BP    BP\n",
      "Actual No BP      3656   1538\n",
      "Actual BP          631   1062\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, \n",
    "    f1_score, roc_auc_score, accuracy_score,\n",
    "    precision_score, recall_score\n",
    ")\n",
    "from xgboost import XGBClassifier as xgb\n",
    "\n",
    "\n",
    "baseline = xgb(\n",
    "    n_estimators=300,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=1.0,\n",
    "    scale_pos_weight=3,    \n",
    "    eval_metric=\"logloss\",\n",
    "    tree_method=\"hist\",\n",
    "    random_state=42\n",
    ")\n",
    "baseline.fit(X_labeled, y_labeled)\n",
    "# Predictions on validation set\n",
    "y_val_pred = baseline.predict(X_val)\n",
    "y_val_proba = baseline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "print(\"=\"*60)\n",
    "print(\"BASELINE MODEL - Validation Set (FIFA 21) Metrics\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nAccuracy:  {accuracy_score(y_val, y_val_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_val, y_val_pred):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_val, y_val_pred):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(y_val, y_val_pred):.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc_score(y_val, y_val_proba):.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"Classification Report:\")\n",
    "print(\"-\"*60)\n",
    "print(classification_report(y_val, y_val_pred, target_names=['No Big Potential', 'Big Potential']))\n",
    "\n",
    "print(\"-\"*60)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(\"-\"*60)\n",
    "cm = confusion_matrix(y_val, y_val_pred)\n",
    "print(f\"                  Predicted\")\n",
    "print(f\"                  No BP    BP\")\n",
    "print(f\"Actual No BP     {cm[0,0]:5d}  {cm[0,1]:5d}\")\n",
    "print(f\"Actual BP        {cm[1,0]:5d}  {cm[1,1]:5d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e53a9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of iteration 1, added 3713 new labels.\n",
      "End of iteration 2, added 2866 new labels.\n",
      "End of iteration 3, added 2340 new labels.\n",
      "End of iteration 4, added 1950 new labels.\n",
      "End of iteration 5, added 1334 new labels.\n",
      "End of iteration 6, added 912 new labels.\n",
      "End of iteration 7, added 633 new labels.\n",
      "End of iteration 8, added 415 new labels.\n",
      "End of iteration 9, added 414 new labels.\n",
      "End of iteration 10, added 407 new labels.\n",
      "End of iteration 11, added 282 new labels.\n",
      "End of iteration 12, added 240 new labels.\n",
      "============================================================\n",
      "SELF-TRAINING MODEL - Validation Set (FIFA 21) Metrics\n",
      "============================================================\n",
      "\n",
      "Accuracy:  0.6659\n",
      "Precision: 0.3928\n",
      "Recall:    0.6580\n",
      "F1 Score:  0.4919\n",
      "ROC-AUC:   0.7118\n",
      "\n",
      "------------------------------------------------------------\n",
      "Classification Report:\n",
      "------------------------------------------------------------\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "No Big Potential       0.86      0.67      0.75      5194\n",
      "   Big Potential       0.39      0.66      0.49      1693\n",
      "\n",
      "        accuracy                           0.67      6887\n",
      "       macro avg       0.62      0.66      0.62      6887\n",
      "    weighted avg       0.74      0.67      0.69      6887\n",
      "\n",
      "------------------------------------------------------------\n",
      "Confusion Matrix:\n",
      "------------------------------------------------------------\n",
      "                  Predicted\n",
      "                  No BP    BP\n",
      "Actual No BP      3472   1722\n",
      "Actual BP          579   1114\n"
     ]
    }
   ],
   "source": [
    "# Evaluate self-training model on validation set (FIFA 21)\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, \n",
    "    f1_score, roc_auc_score, accuracy_score,\n",
    "    precision_score, recall_score\n",
    ")\n",
    "\n",
    "#self-Training classifier\n",
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "from xgboost import XGBClassifier as xgb\n",
    "\n",
    "xgb_baseline = xgb(\n",
    "    n_estimators=300,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=1.0,\n",
    "    scale_pos_weight=3,    \n",
    "    eval_metric=\"logloss\",\n",
    "    tree_method=\"hist\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "self_training = SelfTrainingClassifier(\n",
    "    xgb_baseline,\n",
    "    threshold=0.85,     # XGBoost gives good confidence scores\n",
    "    max_iter=12,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "self_training.fit(X_train_ssl_scaled, y_train_ssl)\n",
    "# Predictions on validation set\n",
    "y_ssl_pred = self_training.predict(X_val_array_scaled)\n",
    "y_ssl_proba = self_training.predict_proba(X_val_array_scaled)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "print(\"=\"*60)\n",
    "print(\"SELF-TRAINING MODEL - Validation Set (FIFA 21) Metrics\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nAccuracy:  {accuracy_score(y_val, y_ssl_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_val, y_ssl_pred):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_val, y_ssl_pred):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(y_val, y_ssl_pred):.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc_score(y_val, y_ssl_proba):.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"Classification Report:\")\n",
    "print(\"-\"*60)\n",
    "print(classification_report(y_val, y_ssl_pred, target_names=['No Big Potential', 'Big Potential']))\n",
    "\n",
    "print(\"-\"*60)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(\"-\"*60)\n",
    "cm = confusion_matrix(y_val, y_ssl_pred)\n",
    "print(f\"                  Predicted\")\n",
    "print(f\"                  No BP    BP\")\n",
    "print(f\"Actual No BP     {cm[0,0]:5d}  {cm[0,1]:5d}\")\n",
    "print(f\"Actual BP        {cm[1,0]:5d}  {cm[1,1]:5d}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "505bbf37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SELF-TRAINING MODEL - Training Set Metrics (Original Labeled Data)\n",
      "============================================================\n",
      "\n",
      "Labeled samples: 6914\n",
      "\n",
      "Accuracy:  0.7102\n",
      "Precision: 0.4499\n",
      "Recall:    0.7379\n",
      "F1 Score:  0.5590\n",
      "ROC-AUC:   0.7925\n",
      "\n",
      "------------------------------------------------------------\n",
      "Classification Report:\n",
      "------------------------------------------------------------\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "No Big Potential       0.89      0.70      0.78      5193\n",
      "   Big Potential       0.45      0.74      0.56      1721\n",
      "\n",
      "        accuracy                           0.71      6914\n",
      "       macro avg       0.67      0.72      0.67      6914\n",
      "    weighted avg       0.78      0.71      0.73      6914\n",
      "\n",
      "------------------------------------------------------------\n",
      "Confusion Matrix:\n",
      "------------------------------------------------------------\n",
      "                  Predicted\n",
      "                  No BP    BP\n",
      "Actual No BP      3640   1553\n",
      "Actual BP          451   1270\n"
     ]
    }
   ],
   "source": [
    "y_labeled_pred = self_training.predict(X_labeled_scaled)\n",
    "y_labeled_proba = self_training.predict_proba(X_labeled_scaled)[:, 1]\n",
    "\n",
    "# Calculate metrics on original labeled data\n",
    "print(\"=\"*60)\n",
    "print(\"SELF-TRAINING MODEL - Training Set Metrics (Original Labeled Data)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nLabeled samples: {len(y_labeled)}\")\n",
    "print(f\"\\nAccuracy:  {accuracy_score(y_labeled, y_labeled_pred):.4f}\")\n",
    "print(f\"Precision: {precision_score(y_labeled, y_labeled_pred):.4f}\")\n",
    "print(f\"Recall:    {recall_score(y_labeled, y_labeled_pred):.4f}\")\n",
    "print(f\"F1 Score:  {f1_score(y_labeled, y_labeled_pred):.4f}\")\n",
    "print(f\"ROC-AUC:   {roc_auc_score(y_labeled, y_labeled_proba):.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"Classification Report:\")\n",
    "print(\"-\"*60)\n",
    "print(classification_report(y_labeled, y_labeled_pred, target_names=['No Big Potential', 'Big Potential']))\n",
    "\n",
    "print(\"-\"*60)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(\"-\"*60)\n",
    "cm = confusion_matrix(y_labeled, y_labeled_pred)\n",
    "print(f\"                  Predicted\")\n",
    "print(f\"                  No BP    BP\")\n",
    "print(f\"Actual No BP     {cm[0,0]:5d}  {cm[0,1]:5d}\")\n",
    "print(f\"Actual BP        {cm[1,0]:5d}  {cm[1,1]:5d}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
